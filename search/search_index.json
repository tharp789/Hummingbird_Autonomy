{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AirStack Boilerplate","text":"<p>Welcome to the AirStack Boilerplate! This repository template serves to kickstart the development of your own robotics autonomy stack. You're encouraged to customize your version in any way to best suit your project's needs.</p> <p>This boilerplate is maintained by the AirLab at Carnegie Mellon University's Robotics Institute.</p> <p>Please head to our Getting Started page to start.</p> <p> AirStack</p>"},{"location":"about/","title":"About","text":"<p>This stack is built and maintained by the AirLab at Carnegie Mellon University's Robotics Institute. </p>"},{"location":"about/#license","title":"License","text":"<p>Not sure yet but probably Apache 2.0 or MIT for the open source parts.</p>"},{"location":"getting_started/","title":"Getting Started","text":"<p>By the end of this tutorial, you will have the autonomy stack running on your machine.</p>"},{"location":"getting_started/#requirements","title":"Requirements","text":"<p>You need at least 25GB free to install the Docker image.</p> <p>Have an NVIDIA GPU &gt;= RTX 3070 to run Isaac Sim locally.</p>"},{"location":"getting_started/#setup","title":"Setup","text":""},{"location":"getting_started/#clone","title":"Clone","text":"<pre><code>git clone --recursive -j8 git@github.com:castacks/AirStack.git\n</code></pre>"},{"location":"getting_started/#docker","title":"Docker","text":"<p>Install Docker Desktop. This should come installed with docker compose.</p>"},{"location":"getting_started/#configure","title":"Configure","text":"<p>Follow the instructions in <code>docker/isaac-sim/omni_pass.env</code> to configure the required settings for your Omniverse Nucelus Server token. To generate a token, follow the NVIDIA docs here. See here for more information:  https://airlab.slite.com/app/docs/X8dZ8w5S3GP9tw</p> <p>Also set the default OMNI_SERVER and accept the license terms. (Basti: The omni_server variable doesn't seem to work. The content browser might have to be edited manually the first time. To do that click: \"Add new connection ...\" and enter airlab-storage.andrew.cmu.edu:8443 in the server field. Also if there is a localhost it should be removed since we are not running a local Nucleus server.</p>"},{"location":"getting_started/#docker-images","title":"Docker Images","text":"<p>Now you have two options on how to proceed. You can build the docker image from scratch or pull the existing image on the airlab docker registry. Building the image from scratch can be  useful if you would like to add new dependencies or add new custom functionality. For most users just pulling the existing image will be more conveninent and fast since it doesn't require access to the Nvidia registry.</p>"},{"location":"getting_started/#option-1-preferred-use-the-airlab-docker-registry","title":"Option 1 (Preferred): Use the Airlab Docker registry","text":"<p>To use the AirLab docker registry do the following <pre><code>cd AirStack/docker/\ndocker login airlab-storage.andrew.cmu.edu:5001\n## &lt;Enter your andrew id (without @andrew.cmu.edu)&gt;\n## &lt;Enter your andrew password&gt;\n\n## Pull the images in the docker compose file\ndocker compose pull \n</code></pre> When you execute docker compose pull in the next step the image will be pulled from the server automatically. This might take a while since the image is large.</p>"},{"location":"getting_started/#option-2-setup-from-scratch","title":"Option 2: Setup from Scratch","text":"<ol> <li> <p>SITL (Required until we add to docker image)</p> <p>Download the Ascent Spirit SITL software packages from this link.</p> <p>Then unzip the file AscentAeroSystemsSITLPackage.zip in this folder: <pre><code>cd AirStack/docker/isaac-sim/\nunzip ~/Downloads/AscentAeroSystemsSITLPackage.zip -d .\n</code></pre></p> </li> <li> <p>Gain access to NVIDIA NGC Containers by following these instructions.</p> <p>Then: <pre><code>cd AirStack/docker/\ndocker compose build  # build the images locally\n</code></pre></p> </li> </ol> <p>IF you have permission you can now push an updated images to the docker server (only if it changed and is required) <pre><code>docker compose push\n</code></pre></p>"},{"location":"getting_started/#launch","title":"Launch","text":""},{"location":"getting_started/#initialize-docker-containers","title":"Initialize Docker Containers","text":"<pre><code>xhost +  # allow docker access to X-Server\n\n# Make sure you are in the AirStack/docker directory.\n\n# Start docker compose services,\n#  you can append `--scale robot=[NUM_ROBOTS]` for more robots, default is 1\ndocker compose up -d\n# view running containers\ndocker ps -a\n</code></pre>"},{"location":"getting_started/#launch-isaac-sim","title":"Launch Isaac Sim","text":"<p><pre><code># in another terminal under AirStack/docker\ndocker exec -it isaac-sim bash\n# within isaac-sim docker\nrunapp\n</code></pre> In the Isaac content browser, under \"Omniverse\", click \"Add New Connection ...\". Type in <code>airlab-storage.andrew.cmu.edu:8443</code>.</p> <p>It takes a few seconds to connect.</p> <p>Then open the stage from the Nucleus server: <code>airlab-storage.andrew.cmu.edu:8443/Projects/AirStack/neighborhood.scene.usd</code></p> <p>Once Isaac Sim launches, hit the gray triangle \"Play\" button on the left side bar. It takes a minute for the GPS to initialize.</p>"},{"location":"getting_started/#launch-robot","title":"Launch Robot","text":"<pre><code># create a bash shell in the docker-robot-1 container\ndocker exec -it docker-robot-1 bash\n\n# in robot docker\nbws &amp;&amp; sws  # build workspace and source workspace. these are aliases in ~/.bashrc\nros2 launch robot_bringup robot.launch.xml\n</code></pre>"},{"location":"getting_started/#move-robot","title":"Move Robot","text":"<p>Find the RQT GUI window. Hit <code>Takeoff</code>, then hit <code>Publish</code> in the trajectory window like in this video:</p> <p>Note you can also use the <code>ros2 topic pub</code> command to move the robot. For example, to fly to a position:</p> <pre><code># start another terminal in docker container\ndocker exec -it docker-robot-1 bash\n# in docker\n# FLY TO POSITION. Put whatever position you want\nros2 topic pub /robot_1/interface/mavros/setpoint_position/local geometry_msgs/PoseStamped \\\n    \"{ header: { stamp: { sec: 0, nanosec: 0 }, frame_id: 'base_link' }, \\\n    pose: { position: { x: 10.0, y: 0.0, z: 20.0 }, orientation: { x: 0.0, y: 0.0, z: 0.0, w: 1.0 } } }\" -1\n</code></pre>"},{"location":"getting_started/#shutdown","title":"Shutdown","text":"<p>To pause containers:</p> <pre><code>docker compose stop\n</code></pre> <p>To shutdown and remove docker containers:</p> <pre><code>docker compose down\n</code></pre>"},{"location":"development/","title":"Developer Guide","text":"<p>Welcome developers! This guide documents how to extend the autonomy stack for your own needs. The stack has been designed with modularity in mind, and aims to make it straight forward to swap out any component.</p> <p>We assume you're developing first on a local machine with simulation.</p>"},{"location":"development/contributing/","title":"Contributing","text":"<p>This page describes how to merge content back into main.</p>"},{"location":"development/contributing/#dependencies","title":"Dependencies","text":"<p>Make sure to add your ROS2 package dependencies to your <code>package.xml</code> file. These get installed when the docker image is built.</p> <p>If you need to add a dependency that's not in the docker image, please add a section to the <code>Dockerfile</code> in the <code>docker/</code> directory.</p>"},{"location":"development/contributing/#documentation","title":"Documentation","text":"<p>Please make sure to document your work. Docs are under <code>AirStack/docs/</code>. The navigation tree is under <code>AirStack/mkdocs.yml</code>.</p> <p>This documentation is built with Material MKDocs. Visit mkdocs.org and mkdocs-material to learn how to use it.</p>"},{"location":"development/contributing/#commands","title":"Commands","text":"<p><pre><code>pip install mkdocs-material\nmkdocs serve\n</code></pre> Launches docs on https://localhost:8000.</p> <ul> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"development/contributing/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"development/contributing/#merge","title":"Merge","text":"<p>Submit a pull request.</p> <p>All tests must pass before merging.</p> <p>Regression tests are run so that we don't break anything.</p>"},{"location":"development/docker_usage/","title":"General Usage with Docker Compose","text":"<p>AirStack is designed for multi-robot development, and is setup to run multiple robots in simulation.</p> <p>To mimic interacting with real world robots, we use Docker Compose to manage Docker containers that isolate the simulation, each robot, and the ground control station.</p> <p>The details of the docker compose setup is in <code>AirStack/docker/docker-compose.yaml</code>.</p> <p>In essence, the compose file launches:</p> <ul> <li>Isaac Sim</li> <li>ground control station</li> <li>robots</li> </ul> <p>all get created on the same default Docker bridge network.  This lets them communicate with ROS2 on the same network.</p> <p>Each robot has its own ROS_DOMAIN_ID.</p>"},{"location":"development/docker_usage/#start-and-stop","title":"Start and Stop","text":"<p>Start <pre><code>docker compose up -d --scale robot=[NUM_ROBOTS]\n\n# see running containers\ndocker ps -a\n</code></pre></p> <p>Stop <pre><code>docker compose down\n</code></pre></p>"},{"location":"development/docker_usage/#ssh-into-robots","title":"SSH into Robots","text":"<p>The containers mimic the robots' onboard computers on the same network. Therefore we intend to interface with the robots through ssh.</p> <p>The <code>ground-control-station</code> and <code>docker-robot-*</code> containers are setup with ssh daemon, so you can ssh into the containers using the IP address.</p> <p>You can get the IP address of each container by running the following command:</p> <p><pre><code>docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' [CONTAINER-NAME]\n</code></pre> Then ssh in, for example: <pre><code>ssh root@172.18.0.6\n</code></pre></p> <p>The ssh password is <code>airstack</code>.</p>"},{"location":"development/docker_usage/#container-details","title":"Container Details","text":""},{"location":"development/docker_usage/#isaac-sim","title":"Isaac Sim","text":"<p>Start a bash shell in the Isaac Sim container: <pre><code>docker exec -it isaac-sim bash\n</code></pre></p> <p><code>runapp</code> launches Isaac Sim. The <code>--path</code> argument can be passed with a path to a <code>.usd</code> file to load a scene.</p> <p>It can also be run in headless mode with <code>./runheadless.native.sh</code> to stream to Omniverse Streaming Client or <code>./runheadless.webrtc.sh</code> to stream to a web browser.</p> <p>The container also has the isaacsim ROS2 package within that can be launched with <code>ros2 launch isaacsim run_isaacsim.launch.py</code>. </p>"},{"location":"development/docker_usage/#robot","title":"Robot","text":"<p>Start a bash shell in a robot container, e.g. for robot_1: <pre><code>docker exec -it docker-robot-1 bash\n</code></pre></p> <pre><code># in robot docker\ncws  # cleans workspace\nbws  # builds workspace\nsws  # sources workspace\nros2 launch robot_bringup robot.launch.xml  # top-level launch \n</code></pre> <p>These aliases are in the <code>~/.bashrc</code> file.</p> <p>Each robot has <code>ROS_DOMAIN_ID</code> set to its ID number. <code>ROBOT_NAME</code> is set to <code>robot_$ROS_DOMAIN_ID</code>.</p>"},{"location":"development/docker_usage/#ground-control-station","title":"Ground Control Station","text":"<p>Currently the ground control station uses the same image as the robot container. This may change in the future.</p> <p>Start a bash shell in a robot container: <pre><code>docker exec -it ground-control-station bash\n</code></pre></p> <p>The commands are currently the same.</p> <p><code>ROS_DOMAIN_ID</code> is set to 0.</p>"},{"location":"development/frame_conventions/","title":"ROS Frame Conventions","text":"<p>Isaac Sim follows the Forward-Left-Up (FLU) coordinate system. This means that the X-axis points forward, the Y-axis points left, and the Z-axis points up. This is the same convention used in the Isaac SDK and Isaac Sim's parent platform, Omniverse. Isaac Docs</p>"},{"location":"development/testing/","title":"Testing","text":""},{"location":"development/testing/ci_cd/","title":"CI/CD Pipeline","text":""},{"location":"development/testing/integration_testing/","title":"Integration Testing","text":""},{"location":"development/testing/testing_frameworks/","title":"Testing Frameworks","text":""},{"location":"development/vscode/","title":"VS Code: Docker Integration and Debugger Setup","text":"<p>Start containers <pre><code># optionally pass the --scale robot=N argument to start N robots\ndc compose up -d  # --scale robot=2\n</code></pre></p> <p>Open AirStack folder</p> <pre><code>cd AirStack\ncode .\n</code></pre> <p>Install the \"Dev Containers\" extension.</p> <p>Now click the \"Remote Explorer\" icon on the left side bar, hover over a robot container, and attach to the container.</p> <p></p> <p>Install recommended extensions within the image. This installs the <code>ROS</code>, <code>C++</code>, and <code>Python</code> extensions in the container. </p>"},{"location":"development/vscode/#build-ros-workspace","title":"Build ROS Workspace","text":"<p>Hit <code>Ctrl-Shift-B</code> to build the project. This is a shortcut for <code>bws --cmake-args '-DCMAKE_BUILD_TYPE=Debug'</code>, which adds debug symbols to the build.</p> <p>Build tasks are defined in <code>.vscode/tasks.json</code>.</p>"},{"location":"development/vscode/#launch","title":"Launch","text":"<p>Hit <code>F5</code> to launch <code>robot.launch.xml</code>, or click the \"Run and Debug\" button on the left side of the screen and click the green play button.</p> <p>Launch tasks are defined in <code>.vscode/launch.json</code>.</p> <p></p> <p>You can now set breakpoints and debug as usual in VSCode.</p> <p>Warning about file permissions</p> <p>Folders and files created within the attached docker container will be owned by root. This can cause issues when trying to edit files from the host machine, especially when using git to switch branches. If you accidentally create files as root, you can change the owner to your user with the following command: <pre><code>sudo chown -R $USER:$USER .\n</code></pre></p>"},{"location":"ground_control_station/","title":"Ground Control Station","text":"<p>The Ground Control Station (GCS) is for operators to monitor and control the robots. </p>"},{"location":"real_world/","title":"Real World Overview","text":"<p>Fly robots in da wild.</p> <p>That's wild.</p>"},{"location":"real_world/installation/","title":"Installation on Hardware","text":""},{"location":"robot/","title":"Robot","text":""},{"location":"robot/#launch-structure","title":"Launch Structure","text":"<p>Each high-level module has a <code>*_bringup</code> package that contains the launch files for that module. The launch files are located in the <code>launch</code> directory of the <code>*_bringup</code> package. The launch files are named <code>*.launch.(xml/yaml/py)</code> and can be launched with <code>ros2 launch &lt;module_name&gt;_bringup &lt;module_name&gt;.launch.(xml/yaml/py)</code>.</p>"},{"location":"robot/autonomy/","title":"Autonomy Modules","text":""},{"location":"robot/autonomy/#modules","title":"Modules","text":"<ul> <li>0_interface</li> <li>1_sensors</li> <li>2_perception</li> <li>3_local</li> <li>4_global</li> <li>5_behavior</li> </ul>"},{"location":"robot/autonomy/#system-diagram","title":"System Diagram","text":""},{"location":"robot/autonomy/0_interface/","title":"Interface","text":"<p>The interface defines the communication between the autonomy stack running on the onboard computer and the robot's control unit. For example, for drones it converts the control commands from the autonomy stack into MAVLink messages for the flight controller.</p> <p>TODO: This is not our diagram, must replace. </p> <p>The code is located under <code>AirStack/ros_ws/src/robot/autonomy/0_interface/</code>.</p>"},{"location":"robot/autonomy/0_interface/#launch","title":"Launch","text":"<p>Launch files are under <code>src/robot/autonomy/0_interface/interface_bringup/launch</code>.</p> <p>The main launch command is <code>ros2 launch interface_bringup interface.launch.xml</code>.</p>"},{"location":"robot/autonomy/0_interface/#robotinterface","title":"RobotInterface","text":"<p>Package <code>robot_interface</code> is a ROS2 node that interfaces with the robot's hardware. The <code>RobotInterface</code> gets robot state and forwards it to the autonomy stack,  and also translates control commands from the autonomy stack into the command for the underlying hardware. Note the base class is unimplemented. Specific implementations should extend <code>class RobotInterface</code> in <code>robot_interface.hpp</code>, for example <code>class MAVROSInterface</code>.</p>"},{"location":"robot/autonomy/0_interface/#state","title":"State","text":"<p>The <code>RobotInterface</code> class broadcasts the robot's pose as a TF2 transform. It also publishes the robot's odometry as a <code>nav_msgs/Odometry</code> message to <code>$(arg robot_name)/0_interface/robot_0_interface/odometry</code>.</p>"},{"location":"robot/autonomy/0_interface/#commands","title":"Commands","text":"<p>The commands are variations of the two main command modes: Attitude control and Position control. These are reflected in MAVLink and supported by both PX4 and Ardupilot.</p> <p>The Robot0_interface node subscribes to:</p> <ul> <li><code>/$(arg robot_name)/interface/cmd_attitude_thrust</code> of type <code>mav_msgs/AttitudeThrust.msg</code></li> <li><code>/$(arg robot_name)/interface/cmd_rate_thrust</code> of type <code>mav_msgs/RateThrust.msg</code></li> <li><code>/$(arg robot_name)/interface/cmd_roll_pitch_yawrate_thrust</code> of type <code>mav_msgs/RollPitchYawrateThrust.msg</code></li> <li><code>/$(arg robot_name)/interface/cmd_torque_thrust</code> of type <code>mav_msgs/TorqueThrust.msg</code></li> <li><code>/$(arg robot_name)/interface/cmd_velocity</code> of type <code>geometry_msgs/TwistStamped.msg</code></li> <li><code>/$(arg robot_name)/interface/cmd_position</code> of type <code>geometry_msgs/PoseStamped.msg</code></li> </ul> <p>All messages are in the robot's body frame, except <code>velocity</code> and <code>position</code> which use the frame specified by the message header.</p>"},{"location":"robot/autonomy/0_interface/#mavrosinterface","title":"MAVROSInterface","text":"<p>The available implementation in AirStack is called <code>MAVROSInterface</code> implemented in <code>mavros_interface.cpp</code>. It simply forwards the control commands to the Ascent flight controller (based on Ardupilot) using MAVROS.</p>"},{"location":"robot/autonomy/0_interface/#custom-robot-interface","title":"Custom Robot Interface","text":"<p>If you're using a different robot control unit with its own custom API, then you need to create an associated RobotInterface. Implementations should do the following:</p>"},{"location":"robot/autonomy/0_interface/#broadcast-state","title":"Broadcast State","text":"<p>Implementations of <code>RobotInterface</code> should obtain the robot's pose and broadcast it as a TF2 transform.</p> <p>Should look something like: <pre><code>// callback function triggered by some loop\nvoid your_callback_function(){\n    // ...\n    geometry_msgs::msg::TransformStamped t;\n    // populate the transform, e.g.:\n    t.header = // some header\n    t.transform.translation.x = // some value\n    t.transform.translation.y = // some value\n    t.transform.translation.z = // some value\n    t.transform.rotation = // some quaternion\n    // Send the transformation\n    this-&gt;tf_broadcaster_-&gt;sendTransform(t);\n    // ...\n}\n</code></pre> TODO: our code doesn't currently do it like this, it instead uses an external odometry_conversion node.</p>"},{"location":"robot/autonomy/0_interface/#override-command-handling","title":"Override Command Handling","text":"<p>Should override all <code>virtual</code> functions in <code>robot_interface.hpp</code>:</p> <ul> <li><code>cmd_attitude_thrust_callback</code></li> <li><code>cmd_rate_thrust_callback</code></li> <li><code>cmd_roll_pitch_yawrate_thrust_callback</code></li> <li><code>cmd_torque_thrust_callback</code></li> <li><code>cmd_velocity_callback</code></li> <li><code>cmd_position_callback</code></li> <li><code>request_control</code></li> <li><code>arm</code></li> <li><code>disarm</code></li> <li><code>is_armed</code></li> <li><code>has_control</code></li> </ul>"},{"location":"robot/autonomy/1_sensors/","title":"Index","text":"<p>We'll fill this with different things like the ZED-X package, LiDAR, etc</p>"},{"location":"robot/autonomy/2_perception/","title":"Perception","text":"<p>These modules process raw sensor data into useful information for the robot. For example: for detecting obstacles, localizing the robot, and recognizing objects.</p> <p>Perception modules typically output topics in image space or point cloud space. This information then gets aggregated into global and local world models later in the pipeline.</p> <p>Common perception modules include:</p> <ul> <li>semantic segmentation</li> <li>VIO (Visual Inertial Odometry)</li> </ul>"},{"location":"robot/autonomy/2_perception/state_estimation/","title":"State estimation","text":"<p>Hey Yuheng your stuff goes here:)</p>"},{"location":"robot/autonomy/3_local/controls/","title":"Local Controls","text":"<p>The controller should publish control commands directly to topics defined by the Robot Interface.</p>"},{"location":"robot/autonomy/3_local/controls/#trajectory-controller","title":"Trajectory Controller","text":""},{"location":"robot/autonomy/3_local/planning/","title":"Local Planning","text":"<p>Part of the local planner is the Waypoint Manager.</p> <p>The Waypoint Manager subscribes to the global waypoints and the drone's current position and publishes the next waypoint to the local planner.</p> <p>We plan for this baseline to be DROAN</p>"},{"location":"robot/autonomy/3_local/world_model/","title":"Local World Model","text":""},{"location":"robot/autonomy/4_global/planning/","title":"Global Planning","text":"<p>Global planners output a high level, coarse trajectory for the robot to follow. </p> <p>A trajectory is a spatial path plus a schedule.  This means each waypoint in the trajectory has a time associated with it, indicating when the robot should reach that waypoint. These timestamps are fed to the local planner and controller to determine velocity and acceleration.</p> <p>If a waypoint's header timestamp is empty, the local planner should assume there's no time constraint and follow the trajectory at its own pace.</p> <p>The global planner should make a trajectory that is collision-free according to the global map. However, avoiding fine obstacles is delegated to the local planner that operates at a faster rate.</p> <p>We intend the global planners to be modular. AirStack implements a basic Random Walk planner as a baseline.  Feel free to implement your own through the following interfaces.</p>"},{"location":"robot/autonomy/4_global/planning/#ros-interfaces","title":"ROS Interfaces","text":"<p>Global planners are meant to be modules that can be swapped out easily.  They can be thought of as different high level behaviors for the robot to follow. The Behavior Executive may run multiple global planners in parallel and choose the best plan for the current situation.</p> <p>As such, the global planner should be implemented as a ROS2 action server that can be queried for a plan. The Behavior Executive will then publish the best plan to <code>/$(arg robot_name)/global/trajectory</code> for the local planner to follow.</p> <pre><code>sequenceDiagram\n  autonumber\n  Behavior Executive-&gt;&gt;Global Planner: GetPlan.action: goal\n  loop Planning\n      Global Planner-&gt;&gt;Behavior Executive: GetPlan.action: feedback\n  end\n  Global Planner--&gt;&gt;Behavior Executive: GetPlan.action: result (nav_msgs/Path)\n  Behavior Executive--&gt;&gt;Local Planner: /$ROBOT_NAME/global/trajectory (nav_msgs/Path)</code></pre>"},{"location":"robot/autonomy/4_global/planning/#actions-interface","title":"Actions Interface","text":"<p>Global Planner implementations should define a custom GetPlan action server and associated <code>GetPlan.action</code> message.  The action message may be defined with whatever input parameters necessary for the planner to generate a plan. Your <code>GetPlan.action</code> must return a <code>nav_msgs/Path</code> message.</p> <p>An example <code>GetPlan.action</code> message is shown below. <pre><code># Define a goal\nstd_msgs/Duration timeout  # maximum time to spend planning\ngeometry_msgs/Polygon bounds # boundary that the plan must stay within\n---\n# Define the result that will be published after the action execution ends.\nnav_msgs/Path trajectory  # REQUIRED FIELD\n---\n# Define a feedback message that will be published during action execution.\nfloat32 percent_complete\n</code></pre></p>"},{"location":"robot/autonomy/4_global/planning/#goal","title":"Goal","text":"<p>The goal defines the parameters that the global planner needs to generate a plan. All fields are optional.</p>"},{"location":"robot/autonomy/4_global/planning/#result","title":"Result","text":"<p>The global planner must have a return field <code>trajectory</code> of message type <code>nav_msgs/Path</code>. <code>trajectory</code> defines high level waypoints to reach by a given time.</p> <p>The <code>nav_msgs/Path</code> message type contains a <code>header</code> field and <code>poses</code> field.</p> <ul> <li>The top level header of <code>nav_msgs/Path</code> message should contain the coordinate frame of the trajectory, and its timestamp should indicate when the trajectory was published.</li> <li>Within the <code>poses</code> field, each <code>geometry_msgs/PoseStamped</code>'s header should contain a timestamp that indicates when that waypoint should be reached</li> </ul> <pre><code>nav_msgs/Path.msg\n    - std_msgs/Header header\n        - time stamp: when the trajectory was generated\n        - frame_id: the coordinate frame of the trajectory\n    - geometry_msgs/PoseStamped[] poses: the trajectory\n        - geometry_msgs/PoseStamped pose\n            - std_msgs/Header header\n                - time stamp: when the waypoint should be reached\n                - string frame_id: the coordinate frame of the waypoint\n            - geometry_msgs/Pose pose: the position and orientation of the waypoint\n</code></pre>"},{"location":"robot/autonomy/4_global/planning/#feedback","title":"Feedback","text":"<p>All other fields are optional.</p> <p>More info about ROS2 actions may be found in the official tutorial and design philosophy documents.</p>"},{"location":"robot/autonomy/4_global/planning/#subscribers","title":"Subscribers","text":"<p>In general, the global planner needs to access components of the world model such as the map and drone state.</p> <p>The most common map is Occupancy Grids that is published by TODO node.</p> <p>The global planner can also access the robot's current state and expected state in the future. For example, if the global planner takes 20 seconds to plan a trajectory,  it can query where the robot expects to be in 20 seconds. This ROS2 service is available under TODO.</p> <p>The global planner can do whatever it wants internally with this information.</p>"},{"location":"robot/autonomy/4_global/planning/#example-planners","title":"Example Planners","text":""},{"location":"robot/autonomy/4_global/planning/#random-walk-planner","title":"Random Walk planner","text":"<p>The random walk planner replans when the robot is getting close to the goal. The random walk planner is a trivial planner that generates a plan by randomly selecting a direction to move in. The random walk planner is useful for testing the robot's ability to follow a plan.</p>"},{"location":"robot/autonomy/4_global/world_model/","title":"Global World Model","text":""},{"location":"robot/autonomy/5_behavior/behavior_tree/","title":"Behavior Trees","text":"<p>De\ufb01nes how a task in terms of conditions and actions which the user implements.</p> <p>Other types of nodes, control \ufb02ow and decorator nodes, control which conditions will be checked and which actions will be activated.</p> <p>Nodes have statuses of either SUCCESS, RUNNING or FAILURE.</p> <p></p>"},{"location":"robot/autonomy/5_behavior/behavior_tree/#why-behavior-trees","title":"Why Behavior Trees?","text":"<p>Maintainable - Easy to modify</p> <p>Scalable - Parts of sub-trees are modular and can be encapsulated</p> <p>Reusable - Sub-trees can be reused in different places</p> <p>Clear visualization and interpretation</p>"},{"location":"robot/autonomy/5_behavior/behavior_tree/#types-of-nodes","title":"Types of Nodes","text":"<ul> <li>Execution Nodes<ul> <li>Condition Nodes</li> <li>Action Nodes</li> </ul> </li> <li>Decorator Nodes<ul> <li>Not Node</li> </ul> </li> <li>Control Flow Nodes<ul> <li>Sequence Nodes</li> <li>Fallback Nodes</li> </ul> </li> </ul>"},{"location":"robot/autonomy/5_behavior/behavior_tree/#execution-nodes-condition-nodes","title":"Execution Nodes - Condition Nodes","text":"<p>Condition nodes have a status of either SUCCESS or FAILURE</p> <p> </p>"},{"location":"robot/autonomy/5_behavior/behavior_tree/#execution-nodes-action-nodes","title":"Execution Nodes - Action Nodes","text":"<p>Action nodes can either be active or inactive</p> <p>An inactive node's status is not checked by the behavior tree, it is shown in white</p> <p>below</p> <p>An active node's status is checked, it can either be SUCCESS (green), RUNNING (blue) or FAILURE (red)</p> <p> </p>"},{"location":"robot/autonomy/5_behavior/behavior_tree/#decorator-nodes-not-nodes","title":"Decorator Nodes - Not Nodes","text":"<p>The not node must have one condition node has a child and inverts the status of the child.</p> <p>If the child's status is SUCCESS, the not node's status will be FAILURE.</p> <p>If the child's status is FAILURE, the not node's status will be SUCCESS.</p> <p></p>"},{"location":"robot/autonomy/5_behavior/behavior_tree/#control-flow-nodes-fallback-nodes","title":"Control Flow Nodes - Fallback Nodes","text":"<p>These nodes are shown with a ?</p> <p>This node returns FAILURE if and only if all of its children return FAILURE</p> <p>If one of its children return RUNNING or SUCCESS, it returns RUNNING or SUCCESS and no subsequent children's statuses are check</p> <p>Below shows a typical example, where an action will only be performed if all of the preceding conditions are false. In this case a drone will only be armed if it is not already armed, it is in o\ufb00board mode and it is stationary</p> <p></p>"},{"location":"robot/autonomy/5_behavior/behavior_tree/#control-flow-nodes-sequence-nodes","title":"Control Flow Nodes - Sequence Nodes","text":"<p>These nodes are shown with a \"-&gt;\"</p> <p>This node returns SUCCESS if and only if all of its children return SUCCESS</p> <p>If one of its children return RUNNING or FAILURE, it returns RUNNING or FAILURE and no subsequent children's statuses are check</p> <p>Below shows a typical example where preceding conditions must be true in order for an action to be performed. In this case the drone will land if the IMU times out and it is in o\ufb00board mode</p> <p></p>"},{"location":"robot/logging/","title":"Logging","text":""},{"location":"simulation/","title":"Simulation","text":"<p>We primarily support Isaac Sim. In the future we plan to support Gazebo.</p>"},{"location":"simulation/docker_network/","title":"Docker network","text":""},{"location":"simulation/docker_network/#overview","title":"Overview","text":"<p>The details of the docker containers setup is in the <code>docker-compose.yaml</code> file in the <code>AirStack/docker</code> directory.</p> <p>Isaac Sim, the ground control station, and robots all get created on the same default Docker bridge network.  This lets them communicate with ROS2 on the same network.</p> <p>Each robot has its own ROS_DOMAIN_ID.</p>"},{"location":"simulation/docker_network/#ssh-into-robots","title":"SSH into Robots","text":"<p>The <code>ground-control-station</code> and <code>docker-robot</code> containers are setup with ssh daemon, so you can ssh into the containers using the IP address.</p> <p>You can get the IP address of each container by running the following command:</p> <p><pre><code>docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' [CONTAINER-NAME]\n</code></pre> Then ssh in, for example: <pre><code>ssh root@172.18.0.6\n</code></pre></p> <p>The ssh password is <code>airstack</code>.</p>"},{"location":"simulation/isaac_sim/","title":"Isaac Sim","text":""},{"location":"simulation/isaac_sim/scene_setup/","title":"Scene Setup","text":""},{"location":"simulation/isaac_sim/scene_setup/#creating-a-new-scene","title":"Creating a New Scene","text":"<p>The easiest way is to reference and copy an existing scene.</p>"},{"location":"simulation/isaac_sim/scene_setup/#ros-publishers-through-omnigraph","title":"ROS Publishers Through OmniGraph","text":""},{"location":"simulation/isaac_sim/scene_setup/#configure-robot-name-ros_domain_id-and-topic-namespaces","title":"Configure Robot Name, ROS_DOMAIN_ID, and Topic Namespaces","text":"<p>Under the Spirit drone prim is an <code>Omnigraph</code> component. This component is used to configure the ROS publishers for the robot. The <code>Omnigraph</code> component has the following fields:</p> <ul> <li><code>robot_name</code>: The name of the robot. This is used as the top-level namespace for ROS topics.</li> <li><code>domain_id</code>: The ROS domain ID. This is used as the <code>ROS_DOMAIN_ID</code> for DDS networking.</li> </ul> <p>The Omnigraph has subgraphs for each ROS publisher type. For example, TFs, Images, and PointClouds. The top-level <code>robot_name</code> and <code>domain_id</code> fields get fed into the subgraphs. The <code>Topic Namespaces</code> field should be set to the topic namespace in the subgraphs. This is used to namespace the ROS topics.</p> <p></p>"},{"location":"simulation/isaac_sim/scene_setup/#customizing-the-omnigraph","title":"Customizing the Omnigraph","text":"<p>Common ROS graphs may be added through the top menu bar: <code>Isaac Utils &gt; Common Graphs &gt; ROS</code>.</p> <p>We recommend copying them into the top-level <code>Omnigraph</code> component. Connect the <code>robot_name</code> and <code>domain_id</code> fields to your workflow. Then, select all the nodes in your workflow, right-click, and create a subgraph.</p>"}]}